{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Machine Learning\n","The code below creates a random forest regressor, which is the main model I discuss in the report. This notebook also contains the material to evaluate the model and answer all of the questions in the second part of the task. These answers are detailed in section 2 of the report. Before runing, make sure that the covariates data file is saved as \"data/tcga.csv\"."]},{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn import metrics\n","import forestci as fci\n"]},{"cell_type":"markdown","metadata":{},"source":["### Global variables"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["CWD = os.path.abspath(os.path.join(os.path.abspath(''), \"..\"))\n","ROOT_DIR = os.path.join(CWD, \"../\")\n","DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load the data\n","This cell can be skipped along with the next cell and the prep-processed datafile loaded instead, but is included here to show how the pre-processing took place."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["data_file = \"tcga.csv\"\n","df = pd.read_csv(os.path.join(DATA_DIR, data_file))"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.1 - Pre-processing\n","This cell pre-processes the code and saves a new version of the data file, so that this step does not need to be repeated every session.\n","If the above cell is skipped to avoid loading the data twice, this cell must also be skipped."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Are there duplicate rows? No\n","Are there any zero-variance features? No\n","The near-zero-variance features: ['gene_332', 'gene_573', 'gene_836', 'gene_837', 'gene_838', 'gene_839', 'gene_841', 'gene_871', 'gene_891', 'gene_1530', 'gene_1534', 'gene_1540', 'gene_1976', 'gene_1977', 'gene_1978', 'gene_2106', 'gene_3063']\n","Are there missing values? 3862128\n"]}],"source":["\"\"\" NB: There are no duplicate rows.\"\"\"\n","duplicate_rows = \"yes\" if len(df) > len(df.drop_duplicates()) else \"No\"\n","print(f\"Are there duplicate rows? {duplicate_rows}\")\n","\"\"\"NB: Are columns are float64 except treatment which is int64.\"\"\"\n","show_dtypes = False\n","if show_dtypes:\n","    print(df.dtypes)\n","\"\"\" NB: There are no columns that contain a single value\n","    (no zero-variance features).\"\"\"\n","zero_variance_features = \"yes\" if len(df.columns) != len(df.loc[:, (df != df.iloc[0]).any()].columns) else \"No\"\n","print(f\"Are there any zero-variance features? {zero_variance_features}\")\n","\"\"\" NB: There are columns that have near-zero variance. These\n","    will not be removed in the first instance, but it is\n","    worth baring them in mind. If we set our threshold for\n","    \"near-zero\" variance to containing less than 1% unique values,\n","    they are: gene_332, gene_573, gene_836, gene_837, gene_838, gene_839,\n","    gene_841, gene_871, gene_891, gene_1530, gene_1534, gene_1540,\n","    gene_1976, gene_1977, gene_1978, gene_2106 and gene_3063.\"\"\"\n","near_zero_v_columns = [col for col in df.columns if len(df[col].unique()) <= len(df[col]) * 0.01 and col != \"treatment\"]\n","print(f\"The near-zero-variance features: {near_zero_v_columns}\")\n","\n","\"\"\" NB: Columns do contain missing values and will be imputed with the median\n","    value. This does not factor the covariance between features, but there\n","    are too many missing values to impute with linear regression.\"\"\"\n","missing_value_count = df.isnull().sum().sum()\n","print(f\"How many missing values are there? {missing_value_count}\")\n","\n","# Impute the missing values\n","df.replace(np.NaN, df.median(), inplace=True)\n","\n","# Save pre-processed dataset to file\n","preprocessed_outfile = os.path.join(DATA_DIR, \"tcga_preprocessed.csv\")\n","df.to_csv(preprocessed_outfile, index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load the pre-processed data file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preprocessed_outfile = os.path.join(DATA_DIR, \"tcga_preprocessed.csv\")\n","df = pd.read_csv(os.path.join(DATA_DIR, preprocessed_outfile))\n","feature_columns = [c for c in df.columns if \"gene_\" in c or c == \"treatment\"]\n","feature_df = df[feature_columns]\n","outcome = df[\"outcome\"]"]},{"cell_type":"markdown","metadata":{},"source":["### Define the train/test split\n","The near-zero-variance columns are also stored here for ease, if we want to remove them from the training set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["near_zero_v_columns = [\n","    \"gene_332\",\n","    \"gene_573\",\n","    \"gene_836\",\n","    \"gene_837\",\n","    \"gene_838\",\n","    \"gene_839\",\n","    \"gene_841\",\n","    \"gene_871\",\n","    \"gene_891\",\n","    \"gene_1530\",\n","    \"gene_1534\",\n","    \"gene_1540\",\n","    \"gene_1976\",\n","    \"gene_1977\",\n","    \"gene_1978\",\n","    \"gene_2106\",\n","    \"gene_3063\",\n","]\n","v_columns = [col for col in feature_columns if col not in near_zero_v_columns]\n","feature_df_no_near_zero_variance = feature_df[v_columns]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    feature_df, outcome, test_size=0.25, random_state=5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.2 - Define the model and fit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["regressor = RandomForestRegressor(\n","    n_estimators=200,\n","    min_samples_leaf=1,\n","    max_samples=0.7,\n","    max_features=\"auto\",\n","    max_depth=4,\n","    random_state=5,\n",")\n","regressor.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### Predict values\n","Use the model to predict both the train and test sets and store these values in two dataframes. The predicted test values are used to evaluate the model. Comparing the error in the predicted values for each set shows the extent of over-fitting of the model.  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = regressor.predict(X_test)\n","y_pred_train = regressor.predict(X_train)\n","\n","pred_df = pd.DataFrame(\n","    data={\n","        \"outcome\": y_test,\n","        \"RF_Prediction\": y_pred,\n","        \"error\": abs(y_test - y_pred),\n","        \"squared_error\": (y_test - y_pred) ** 2,\n","    }\n",")\n","\n","pred_df_train = pd.DataFrame(\n","    data={\n","        \"outcome\": y_train,\n","        \"RF_Prediction\": y_pred_train,\n","        \"error\": y_train - y_pred_train,\n","        \"squared_error\": (y_train - y_pred_train) ** 2,\n","    }\n",")\n","display(pred_df)"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.3 and 2.5 - Model Evaluation\n","Print the Root Mean Squared Error (RMSE) and $R^{2}$ for each set of predicted values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\n","    \"Training RMSE: \",\n","    metrics.mean_squared_error(y_train, y_pred_train, squared=False),\n",")\n","print(\n","    \"Test RMSE: \",\n","    metrics.mean_squared_error(y_test, y_pred, squared=False),\n",")\n","\n","print(\"Training R^2: \", metrics.r2_score(y_train, y_pred_train))\n","print(\"Test R^2: \", metrics.r2_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.5 - Uncertainty - not working\n","The following \"commented out\" cell was intended to calculate and plot the uncertainties in any given predicted value, the below code does not work as the random_forest_error currently fails to produce error values when calibrated. When uncalibrated it produces invalid values. If given more time, I would like to explore a possible work-around for this, as discussed in these open issues ([#72](https://github.com/scikit-learn-contrib/forest-confidence-interval/issues/72), [#78](https://github.com/scikit-learn-contrib/forest-confidence-interval/issues/78), and [#83](https://github.com/scikit-learn-contrib/forest-confidence-interval/issues/83)) in github."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Calculate the variance\n","# # Plot predicted outcome without error bars\n","# plt.scatter(pred_df[\"outcome\"], pred_df[\"RF_Prediction\"])\n","# plt.xlabel(\"Reported outcome\")\n","# plt.ylabel(\"Predicted outcome\")\n","# plt.show()\n","\n","# # Calculate the variance - More work required to get fci.random_forest_error working\n","# outcome_forrest_error = fci.random_forest_error(regressor, X_train, X_test, calibrate=True)\n","\n","# # Plot error bars for predicted outcome using unbiased variance\n","# plt.errorbar(pred_df[\"outcome\"], pred_df[\"RF_Prediction\"], yerr=np.sqrt(outcome_forrest_error), fmt=\"o\")\n","# plt.xlabel(\"Reported outcome\")\n","# plt.ylabel(\"Predicted outcome\")\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["###  Task 2.4 - Model errors"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Here are the rows in the top 1% for squared error:\")\n","display(pred_df.nlargest(len(pred_df) // 100, columns=\"squared_error\", keep=\"all\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.6 - Feature importance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["drop_treatment = False\n","\n","feature_importance_df = pd.DataFrame(\n","    data={\n","        \"Feature\": [f\"gene_{i}\" for i in range(4000)] + [\"treatment\"],\n","        \"importance\": regressor.feature_importances_,\n","    }\n",")\n","if drop_treatment:\n","    feature_importance_df = feature_importance_df.drop(\n","        feature_importance_df.tail(1).index, inplace=True\n","    )\n","    n = 20\n","else:\n","    n = 21\n","    \n","feature_importance_df.plot()\n","display(feature_importance_df.nlargest(n, columns=\"importance\", keep=\"all\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2.2 and 2.3 further - Grid searches and analysis\n","The below code sets up several cross-validated grid searches for hyper-parameter tuning. It then outputs the results to a file and plots the performance of the model as different parameters are varied."]},{"cell_type":"markdown","metadata":{},"source":["Set up and fit grid search"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["regressor = RandomForestRegressor(random_state=5)\n","params = {\n","    \"n_estimators\": [100, 200],\n","    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n","    \"max_depth\": [4, 6, 8],\n","    \"criterion\": [\"squared_error\", \"absolute_error\"],\n","}\n","CV_regressor = GridSearchCV(\n","    estimator=regressor, param_grid=params, n_jobs=-1, cv=3, verbose=2\n",")\n","CV_regressor.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Output and display results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cv_results = pd.DataFrame(data=CV_regressor.cv_results_)\n","cv_outfile = os.path.join(ROOT_DIR, \"output/random-forest_gridsearch_results.csv\")\n","cv_results.to_csv(cv_outfile, index=False)\n","display(pd.DataFrame(data=CV_regressor.cv_results_))"]},{"cell_type":"markdown","metadata":{},"source":["Plot bar chart for results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for idx, group in cv_results.groupby(\n","    by=[\"param_max_depth\", \"param_criterion\", \"param_n_estimators\"]\n","):\n","    fig, ax = plt.subplots()\n","    max_features = [\"auto\", \"sqrt\", \"log2\"]\n","    x_pos = range(len(max_features))\n","    auto_mean = group.loc[group[\"param_max_features\"] == \"auto\"][\n","        \"mean_test_score\"\n","    ].values[0]\n","    sqrt_mean = group.loc[group[\"param_max_features\"] == \"sqrt\"][\n","        \"mean_test_score\"\n","    ].values[0]\n","    log2_mean = group.loc[group[\"param_max_features\"] == \"log2\"][\n","        \"mean_test_score\"\n","    ].values[0]\n","    auto_std = group.loc[group[\"param_max_features\"] == \"auto\"][\n","        \"std_test_score\"\n","    ].values[0]\n","    sqrt_std = group.loc[group[\"param_max_features\"] == \"sqrt\"][\n","        \"std_test_score\"\n","    ].values[0]\n","    log2_std = group.loc[group[\"param_max_features\"] == \"log2\"][\n","        \"std_test_score\"\n","    ].values[0]\n","\n","    test_scores = [auto_mean, sqrt_mean, log2_mean]\n","    error = [auto_std, sqrt_std, log2_std]\n","    ax.bar(\n","        x_pos,\n","        test_scores,\n","        yerr=error,\n","        align=\"center\",\n","        alpha=0.5,\n","        ecolor=\"black\",\n","        capsize=10,\n","    )\n","    ax.set_ylabel(\"Test score\")\n","    ax.set_xlabel(\"max_features\")\n","    ax.set_xticks(x_pos)\n","    ax.set_xticklabels(max_features)\n","    ax.set_title(\n","        f\"max_features comparison - max_depth={idx[0]}, criterion={idx[1]}, n_estimators={idx[2]}\"\n","    )\n","    ax.yaxis.grid(True)\n","\n","    # Save the figure and show\n","    plt.tight_layout()\n","    max_features_comparison_plot_file = os.path.join(\n","        ROOT_DIR,\n","        f\"output/machine_learning_plots/criterion_comparison_max_depth={idx[0]}_criterion={idx[1]}_n_estimators={idx[2]}.png\",\n","    )\n","    plt.savefig(max_features_comparison_plot_file, bbox_inches=\"tight\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for idx, group in cv_results.groupby(\n","    by=[\"param_max_features\", \"param_criterion\", \"param_n_estimators\"]\n","):\n","    fig, ax = plt.subplots()\n","    max_depth = [\"4\", \"6\", \"8\"]\n","    x_pos = range(len(max_depth))\n","    mean_4 = group.loc[group[\"param_max_depth\"] == 4][\"mean_test_score\"].values[0]\n","    mean_6 = group.loc[group[\"param_max_depth\"] == 6][\"mean_test_score\"].values[0]\n","    mean_8 = group.loc[group[\"param_max_depth\"] == 8][\"mean_test_score\"].values[0]\n","    std_4 = group.loc[group[\"param_max_depth\"] == 4][\"std_test_score\"].values[0]\n","    std_6 = group.loc[group[\"param_max_depth\"] == 6][\"std_test_score\"].values[0]\n","    std_8 = group.loc[group[\"param_max_depth\"] == 8][\"std_test_score\"].values[0]\n","\n","    test_scores = [mean_4, mean_6, mean_8]\n","    error = [std_4, std_6, std_8]\n","    ax.bar(\n","        x_pos,\n","        test_scores,\n","        yerr=error,\n","        align=\"center\",\n","        alpha=0.5,\n","        ecolor=\"black\",\n","        capsize=10,\n","    )\n","    ax.set_ylabel(\"Test score\")\n","    ax.set_xlabel(\"max_depth\")\n","    ax.set_xticks(x_pos)\n","    ax.set_xticklabels(max_depth)\n","    ax.set_title(\n","        f\"max_depth comparison - param_max_features={idx[0]}, criterion={idx[1]}, n_estimators={idx[2]}\"\n","    )\n","    ax.yaxis.grid(True)\n","    if idx[0] == \"auto\":\n","        ax.set_ylim(ymin=0.7)\n","\n","    # Save the figure and show\n","    plt.tight_layout()\n","    max_depth_comparison_plot_file = os.path.join(\n","        ROOT_DIR,\n","        f\"output/machine_learning_plots/criterion_comparison_param_max_features={idx[0]}_criterion={idx[1]}_n_estimators={idx[2]}.png\",\n","    )\n","    plt.savefig(max_depth_comparison_plot_file, bbox_inches=\"tight\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["regressor2 = RandomForestRegressor(random_state=5)\n","params = {\n","    \"n_estimators\": [100],\n","    \"max_features\": [\"auto\"],\n","    \"max_depth\": [4, 6, 8, 10, 12, 14, None],\n","    \"criterion\": [\"squared_error\"],\n","}\n","CV_regressor2 = GridSearchCV(estimator=regressor2, param_grid=params, cv=3, verbose=2)\n","CV_regressor2.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cv_results2 = pd.DataFrame(data=CV_regressor2.cv_results_)\n","cv_outfile2 = os.path.join(ROOT_DIR, \"output/random-forest_search for max depth.csv\")\n","cv_results2.to_csv(cv_outfile2, index=False)\n","display(pd.DataFrame(data=CV_regressor2.cv_results_))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots()\n","max_depths = [4, 6, 8, 10, 12, 14, \"None\"]\n","x_pos = range(len(max_depths))\n","test_scores = cv_results2[\"mean_test_score\"]\n","error = cv_results2[\"std_test_score\"]\n","ax.bar(\n","    x_pos,\n","    test_scores,\n","    yerr=error,\n","    align=\"center\",\n","    alpha=0.5,\n","    ecolor=\"black\",\n","    capsize=10,\n",")\n","ax.set_ylabel(\"Test score\")\n","ax.set_xlabel(\"max_depth\")\n","ax.set_xticks(x_pos)\n","ax.set_xticklabels(max_depths)\n","ax.set_title(f\"max_depth vs test_score\")\n","ax.yaxis.grid(True)\n","ax.set_ylim(ymin=0.7)\n","\n","# Save the figure and show\n","plt.tight_layout()\n","max_depth_comparison_plot_file = os.path.join(\n","    ROOT_DIR, f\"output/machine_learning_plots/max_depth_line_plot.png\"\n",")\n","plt.savefig(max_depth_comparison_plot_file, bbox_inches=\"tight\")\n","plt.show()"]}],"metadata":{"interpreter":{"hash":"ad8d43620b3925f08ce110e9037cdfdf522485435230516688e36481e087fe75"},"kernelspec":{"display_name":"Python 3.9.7 ('env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
